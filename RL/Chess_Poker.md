# Chess and Poker

## Chess
- M. Campbell, A. J. Hoane, and F. hsiung Hsu. Deep blue. Artificial intelligence, 2002.

## Go
- Alpha Go:
	- D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. van den Driessche, J. Schrittwieser, I. Antonoglou, V. Panneershelvam, M. Lanctot, S. Dieleman, J. Nham, N. Kalchbrenner, I. Sutskever, T. Lillicrap, M. Leach, K. Kavukcuoglu, T. Graepel, and D. Hassabis. Mastering the game of go with deep neural networks and tree search. Nature, 2014.
	- Mastering the game of Go without human knowledge
- PhoenixGo
	- https://github.com/Tencent/PhoenixGo
- MuGo
	- https://github.com/brilee/MuGo
- Leela
	- https://github.com/gcp/leela-zero
- MiniGo:
	- https://github.com/tensorflow/minigo
- ELF:
	- Y. Tian and Y. Zhu. Better computer go player with neural network and long- term prediction. arxiv, 2015.
	- ELF2
- Legacy:
	- P. Baudis and J. loup Gailly. Pachi: State of the art open source go program. Advances in Computer Games, 2012.
	- C. Clark and A. Storkey. Teaching deep convolutional neural networks to play go. ICML, 2015.
	- M. Enzenberger. The integration of a priori knowledge into a go playing neural network. URL: http://www.markus-enzenberger.de/neurogo.html, 1996.
	- M. Enzenberger. an open-source framework for board games and go engine based on monte carlo tree search. Computational Intelligence and AI in Games, IEEE Transactions on., 2010.
	- C. Maddison, A. Huang, I. Sutskever, and D. Silver. Move evaluation in go using deep convolutional neural networks. arxiv, 2014.
	- D. Silver, G. Lever, N. Heess, T. Degris, D. Wierstra, and M. Riedmiller. Deterministic policy gradient algorithms. ICML, 2014.
	- D. Silver, Temporal-Difference Search in Computer Go, 2012

# Gammon
- Gerald Tesauro. Temporal difference learning and td-gammon. Communications of the ACM, 38(3):58–68, 1995.

# Poker (Texas Hod'em)
- Imperfect information Game
- CFR (Counterfactural Regret Minimization)
	- Zinkevich, M., Johanson, M., Bowling, M., & Piccione, C. Regret minimization in games with incomplete information, NIPS 2008
	- Lanctot, M., Waugh, K., Zinkevich, M., & Bowling, M, Monte Carlo sampling for regret minimization in extensive games, NIPS 2009
	- Johanson, M., Bard, N., Lanctot, M., Gibson, R., & Bowling, M, Efficient Nash equilibrium approximation through Monte Carlo counterfactual regret minimization, 2012
	- Johanson, M., Waugh, K., Bowling, M., & Zinkevich, M. Accelerating best response calculation in large extensive games, AAAI 2011
	- Codes: https://github.com/tansey/pycfr
	- A simple (Rock-Paper-Scissors) codes: https://hackernoon.com/artificial-intelligence-poker-and-regret-part-1-36c78d955720
- Noam Brown, Tuomas Sandholm. (CMU)
	- Safe and Nested Subgame Solving for Imperfect-Information Games, NIPS 2017
	- Libratus: The Superhuman AI for No-Limit Poker, IJCAI 2017
	- Reduced Space and Faster Convergence in Imperfect-Information Games via Pruning, ICML 2017

# Rubik's Cube
- Basics:
	- How to solve the rubik’s cube - beginners method. https://ruwix.com/the-rubiks-cube/how-to-solve-the-rubiks-cube-beginners-method/.
- Mathematics:
	- Daniel Kunkle and Gene Cooperman. Twenty-six moves suffice for rubik’s cube. ISSAC ’07
	- Silviu Radu. Rubik’s cube can be solved in 34 quarter turns. http://cubezzz.dyndns.org/drupal/?q=node/view/92, Jul 2007.
	- Michael Reid. Superflip requires 20 face turns. http://www.math.rwth-aachen.de/~Martin.Schoenert/Cube-Lovers/michael_reid__superflip_requires_20_face_turns.html, Jan 1995.
	- Tomas Rokicki. Twenty-two moves suffice for rubik’s cubeR . The Mathematical Intelligencer, 32(1):33–40, 2010.
	- Tomas Rokicki. God’s number is 26 in the quarter-turn metric. http://www.cube20.org/qtm/, Aug 2014
	- Tomas Rokicki, Herbert Kociemba, Morley Davidson, and John Dethridge. The diameter of the rubik’s cube group is twenty. SIAM Review, 56(4):645–670, 2014.
	-  Morwen Thistlethwaite. Thistlethwaite’s 52-move algorithm. https://www.jaapsch.net/puzzles/thistle.htm, Jul 1981.
- Legacy:
	- Peter Lichodzijewski and Malcolm Heywood. The rubik cube and gp temporal sequence learning: an initial study. In Genetic Programming Theory and Practice VIII, pages 35–54. Springer, 2011.
-  **Korf**:
	- Andrew Brown. Rubik’s cube solver. https://github.com/brownan/Rubiks-Cube-Solver, 2017.
	- Deepening A* search.
	- Richard E. Korf. Finding optimal solutions to rubik’s cube using pattern databases. AAAI’97/IAAI’97, pages 700–705. AAAI
- **Kociemba**:
	-  Two-phase algorithm details. http://kociemba.org/math/imptwophase.htm.
	- Maxim Tsoy. Kociemba. https://github.com/muodov/kociemba, 2018.
- Deep-learning:
	- Robert Brunetto and Otakar Trunda. Deep heuristic-learning in the rubik’s cube domain: an experimental evaluation. 2017.